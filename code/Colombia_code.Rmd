---
title: "Colombia_code"
authors: "Chloe, Weilin, Gaby"
output: pdf_document
date: "2025-04-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=60), tidy=TRUE) 
```

```{r package, message=FALSE}
library(readxl)
library(openxlsx)
library(dplyr)
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
library(writexl)
library(tsibble)
library(fable)
library(fable.prophet)

```

## Importing Data
```{r}

#importing data
Colombia_pre_uncleaned <- read_excel("../data/Colombia_precipitation.xlsx")   # I changed the to the relative address 

colSums(is.na(Colombia_pre_uncleaned))
Colombia_pre_uncleaned$DJF[is.na(Colombia_pre_uncleaned$DJF)] <- mean(Colombia_pre_uncleaned$DJF, na.rm = TRUE)
colSums(is.na(Colombia_pre_uncleaned))

write.csv(Colombia_pre_uncleaned, "../data/processed_colombia_precipitation.csv", row.names = FALSE)

colombia_pre <- read_csv("../data/processed_colombia_precipitation.csv")

head(colombia_pre)
nvar <- ncol(colombia_pre) - 1
nobs <- nrow(colombia_pre)

```


## Data Cleaning & TS Creation
```{r}

c_monthly_data <- colombia_pre %>%
  select(YEAR, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, DEC)

c_monthly_data_long <- c_monthly_data %>%
  pivot_longer(cols = JAN:DEC, names_to = "Month", values_to = "Precipitation")

c_monthly_data_long <- c_monthly_data_long %>%
  mutate(Month_Num = match(tolower(Month), tolower(month.abb)),
         Date = as.Date(paste(YEAR, Month_Num, "01", sep = "-")),
         .before = 1) %>%
  arrange(Date)

write.csv(c_monthly_data_long, "../data/colombiamonthly_data_long.csv", row.names = FALSE)

kable(head(c_monthly_data_long, 10),
      caption = "First 10 Rows of Monthly Precipitation Data for Colombia")


```

## Creating Time Series Object
```{r}

c_ts_monthly <- ts(c_monthly_data_long$Precipitation, 
                 start = c(1901,1), frequency = 12)

```


## Initial Plots
```{r}
autoplot(c_ts_monthly) +
  ggtitle("Monthly Precipitation Time Series (Colombia)") +
  xlab("Year") +
  ylab("Precipitation (mm)") +
  theme_minimal()

par(mfrow=c(1,2))
acf(c_ts_monthly, lag.max = 48, main="ACF (Colombia)")
pacf(c_ts_monthly, lag.max = 48, main="PACF (Colombia)")
par(mfrow=c(1,1))
```
**Interpretation:** The time series graph seems to show seasonality as there are visible peaks and troughs, consistent with a seasonal climate.There’s no clear upward or downward trend, suggesting the mean precipitation level has remained relatively stable over time. Moreover, although there’s variation in the amplitude showing more extreme years, this doesn’t appear to be systematically increasing or decreasing.

The ACF shows a wave like pattern, and the significant autocorrelation at multiple repetitive lags suggests strong seasonality, likely due to Colombia's bi-modal rainy seasons. The PACF has a significant spike at lag 1 and smaller spikes at subsequent lags, suggesting  a short-term auto regressive (AR) component, where current precipitation is influenced by the previous month or two.


## Testing and Training
```{r}
c_train_precipitation <- window(c_ts_monthly, end = c(2020, 12))

c_h <- 240

c_total_months <- length(c_ts_monthly)

c_test_precipitation <- window(c_ts_monthly, start = c(2021, 1), end = c(2024, 12))

autoplot(c_train_precipitation)
autoplot(c_test_precipitation)
```

## Decomposing Time Series
```{r}

# Decompose using additive model
c_decompose_monthly <- decompose(c_ts_monthly,"additive")
plot(c_decompose_monthly)

#Creating non-seasonal time series
c_deseasonal_monthly <- seasadj(c_decompose_monthly)  

# Decompose using multiplicative
c_mult_decompose_monthly <- decompose(c_ts_monthly, "multiplicative")
plot(c_mult_decompose_monthly)

```
**Interpretation:** 
Additive Model - the trend shows some variability across the years, but there's no clear increasing or decreasing pattern over time, more just oscillation representing variability instead of a linear trend.The seasonal component is constant over time, showing strong seasonality over the years, which is logical given rain patterns. The residuals appear roughly stable, with some years having anomylous peaks and trough representing random occurrences, but the centered nature of the residual component demonstrates that the additive model is a relatively good fit.

Multiplicative Model - The trend component is practically the same as in the additive model indicating that there is no increasing or decreasing linear trend.The seasonal component also looks the same, even though now the seasonal component is proportional to the trend, indicating no major changes. The residuals also appear relatively stable with some anomilies (more than in the additive model).


## Detrending
```{r}

c_nvar2 <- ncol(c_monthly_data_long) - 1
c_nobs2 <- nrow(c_monthly_data_long)
t <- c(1:c_nobs2)

# Fit a linear trend to TS
c_linear_trend_model <- lm(c_monthly_data_long$Precipitation ~ t)
summary(c_linear_trend_model)

```
**Interpretation:**
The slope is -0.000839mm/month of rain, indicating a very small but slight negative trend in precipitation. Nonetheless, the p-value is 0.852, which is considerably higher than 0.05, meaning that it's not statistically significant. The t value of 0.187 is also very close to 0 which indicates no meaningful relationship between monthly precipitation and time.

## ARIMA
```{r}

c_fit_arima <- auto.arima(c_train_precipitation)
c_pre_arima <- forecast(c_fit_arima, h = 360)

plot(c_pre_arima, main = "ARIMA Forecast (Colombia)")

#Plot model + observed data
autoplot(c_ts_monthly) +
  autolayer(c_pre_arima, series="ARIMA",PI=FALSE) +
  ylab("Precipitation (mm)")

```

## STL + ETS
```{r}

c_pre_stl_ets <- stlf(c_train_precipitation, h = 360, method = "ets")
plot(c_pre_stl_ets, main = "STL + ETS Forecast (Colombia)")

#Plot model + observed data
autoplot(c_ts_monthly) +
  autolayer(c_pre_stl_ets, series="STL + ETS",PI=FALSE) +
  ylab("Precipitation (mm)")

```

## ARIMA + Fourier terms
```{r}

K <- 6
c_fourier_train <- fourier(c_train_precipitation, K = K)
c_fourier_future <- fourier(c_train_precipitation, K = K, h = 360)
c_fit_fourier <- auto.arima(c_train_precipitation, xreg = c_fourier_train, seasonal = FALSE)
c_pre_fourier <- forecast(c_fit_fourier, xreg = c_fourier_future, h = 360)

plot(c_pre_fourier, main = "ARIMA + Fourier Forecast (Colombia)")

#Plot model + observed data
autoplot(c_ts_monthly) +
  autolayer(c_pre_fourier, series="ARIMA + Fourier terms",PI=FALSE) +
  ylab("Precipitation (mm)")

```

## TBATS
```{r}

c_fit_tbats <- tbats(c_train_precipitation)
c_pre_tbats <- forecast(c_fit_tbats, h = 360)
plot(c_pre_tbats, main = "TBATS Forecast (Colombia)")

#Plot model + observed data
autoplot(c_ts_monthly) +
  autolayer(c_pre_tbats, series="TBATS",PI=FALSE) +
  ylab("Precipitation (mm)")

```

## Neural Network
```{r}

c_fit_nnetar <- nnetar(c_train_precipitation)
c_pre_nnetar <- forecast(c_fit_nnetar, h = 360)
plot(c_pre_nnetar, main = "NNETAR Forecast (Colombia)")

#Plot model + observed data
autoplot(c_ts_monthly) +
  autolayer(c_pre_nnetar, series="Neural Network",PI=FALSE) +
  ylab("Precipitation (mm)")

```


## Scores
```{r}

#Model 1: ARIMA
c_ARIMA_scores <- accuracy(c_pre_arima$mean,c_test_precipitation)  

#Model 2: STL + ETS
c_ETS_scores <- accuracy(c_pre_stl_ets$mean,c_test_precipitation)  

#Model 3: ARIMA + Fourier 
c_ARIMAF_scores <- accuracy(c_pre_fourier$mean,c_test_precipitation)

# Model 4:  TBATS 
c_TBATS_scores <- accuracy(c_pre_tbats$mean,c_test_precipitation)

# Model 5:  Neural Network 
c_NN_scores <- accuracy(c_pre_nnetar$mean,c_test_precipitation)

```

```{r}

#create data frame
c_scores <- as.data.frame(
  rbind(c_ARIMA_scores, c_ETS_scores, c_ARIMA_scores, c_TBATS_scores, c_NN_scores)
  )
row.names(c_scores) <- c("ARIMA", "STL+ETS", "ARIMA+Fourier","TBATS","NN")

#choose model with lowest RMSE
c_best_model_index <- which.min(c_scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(c_scores[c_best_model_index,])) 

```

```{r}

kbl(c_scores, 
      caption = "Forecast Accuracy for Precipitation in Colombia",
      digits = array(5,ncol(c_scores))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(c_scores[,"RMSE"]))

```

## Visual Model Comparison
```{r}

autoplot(c_test_precipitation) +
  autolayer(c_pre_arima, PI=FALSE, series="ARIMA") +
  autolayer(c_pre_stl_ets, PI=FALSE, series="STL+ETS") +
  autolayer(c_pre_fourier, PI=FALSE, series="ARIMA + Fourier") +
  autolayer(c_pre_tbats,PI=FALSE, series="TBATS") +
  autolayer(c_pre_nnetar,PI=FALSE, series="NN") +
  xlab("Year") + ylab("Precipitation(mm)") + 
  ggtitle("Colombia Visual Model Comparison") + 
  guides(colour=guide_legend(title="Forecast"))


```

**Interpretation:**
ARIMA:
The ARIMA model captures seasonality relatively well, but the forecast band is wide, indicating increasing uncertainty over time. It has the lowest RMSE meaning the smallest magnitude of error and the best Theil U score, indicating that the model performs well compared to a naive model. 

STL + ETS:
The STL + ETS model shows a smooth forecast curve with seasonality retained. Although the variance increases, it remains relatively controlled. The model has the best MAPE, meaning that the average magnitude of the errors is the lowest, and the best residual autocorrelation, indicating that more of the errors are random and not correlated with previous error.

ARIMA + Fourier:
This model is similar to regular ARIMA, but it captures cyclical seasonal components more clearly, which may not be so necessary here since the accuracy scores are the same as the ARIMA model.

TBATS:
TBATS shows an aggressive increase in forecast uncertainty, which may indicate model over fitting or extrapolation issues. The forecast seems relatively unstable after 2030, and none of the accuracy scores outperform the other models, indicating that it isn't the best fit.

NNETAR:
This model captures the general seasonal shape, but the forecast appears more rigid and less sensitive to variation. It is the worst performer across the models, with a high RMSE indicating a high magnitude of error, a high MAPE, and the worst Theil's U. Therefore, NNETAR isn't a good fit.

